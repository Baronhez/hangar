# The AWS Service Connection name created in Azure DevOps
awsServiceConnection="AWS-Terraform-Connection"

# Comma separated list of flags. Make sure to end with a comma, Eg: $name,$xyz,
mandatoryFalgs="$pipelineName,$configFile,$localDirectory,$s3Bucket,$s3KeyPath,$clusterName,"
# Path to the templates.
templatesPath="scripts/pipelines/azure-devops/templates/eks"
# YAML file name.
yamlFile="eks-provisioning.yml"
# Source branch.
sourceBranch="feature/eks-provisioning"
# Path to the pipelines.
pipelinePath=".pipelines"
# Path to terraform templates.
terraformTemplatesPath="scripts/environment-provisioning/aws/eks"
# Path to terraform scripts.
terraformPath=".terraform/eks"

# Function that copies the terraform scripts into the directory.
function copyScript {
    # Check if the .terraform folder exists.
    if [ -d "${localDirectory}/.terraform" ]
    then
        # The folder .terraform exists.
        # Check if the eks folder exists inside the terraform folder.
        if [ ! -d "${localDirectory}/${terraformPath}" ]
        then
            # The folder does not exist.
            # Create the eks folder.
            cd "${localDirectory}/.terraform"
            mkdir "eks"
        fi
    else
        # The folder .terraform does not exist.
        # Create the .terraform folder.
        cd "${localDirectory}"
        mkdir ".terraform"

        # Create the eks folder.
        cd "${localDirectory}/.terraform"
        mkdir "eks"
    fi

    cd "${hangarPath}/${terraformTemplatesPath}"

    cp * "${localDirectory}/${terraformPath}"

    # Check if an extra artifact to store is supplied.
    if test ! -z "$artifactPath"
    then
        # Add the extra step to the YAML.
        cat "${hangarPath}/${templatesPath}/store-extra-path.yml" >> "${localDirectory}/${scriptFilePath}/${yamlFile}"
    fi
}

# Function that adds the variables to be used in the pipeline.
function addPipelineVariables {
    # Add the extra artifact to store variable.
    az pipelines variable create --name "artifactPath" --pipeline-name ${pipelineName} --value ${artifactPath}

    # Add the AWS service coonection variable.
    az pipelines variable create --name "awsServiceConnection" --pipeline-name ${pipelineName} --value ${awsServiceConnection}

    # Add the AWS S3 bucket name variable.
    az pipelines variable create --name "s3Bucket" --pipeline-name ${pipelineName} --value ${s3Bucket}

    # Add the AWS S3 Key path variable.
    az pipelines variable create --name "s3KeyPath" --pipeline-name ${pipelineName} --value ${s3KeyPath}

    # Add the AWS S3 Key path variable.
    az pipelines variable create --name "clustername" --pipeline-name ${pipelineName} --value ${clusterName}

    #Create PAT to manage variable group and add pipeline variable
    #Get organization
    cd "${localDirectory}"
    organization=$(git config --get remote.origin.url)
    organization=$(echo $organization | cut -d/ -f4)
    echo -e "${green}Creating a PAT with necessary permissions..."
    patToken=$(az rest --method post --uri "https://vssps.dev.azure.com/$organization/_apis/tokens/pats?api-version=7.1-preview.1" --resource "https://management.core.windows.net/" --body '{ "displayName": "CreateEKSVariablesToken", "validTo": "2099-02-25T11:44:36.1966667Z", "scope": "vso.variablegroups_manage vso.build_execute" }')
    patToken=$(echo "$patToken" | python -c  "import sys, json; print(json.load(sys.stdin)['patToken']['token'])")
    az pipelines variable create --name "pat" --pipeline-name ${pipelineName} --value $patToken

}